<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Andrea Simonelli</title>
  
  <meta name="author" content="Andrea Simonelli">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Andrea Simonelli</name>
              </p>
              <p>
                I am a Research Engineer at Meta in Zurich (Switzerland), where I work on computer vision and machine learning.  
              </p>

              <p>
              I did my PhD at the University of Trento (Italy). My advisors were prof. Elisa Ricci (University of Trento) and dr. Samuel Rota Bulo' (Meta).
              </p>

              <p style="text-align:center">
                <a href="mailto:simonelli.andrea23@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=wK2I1ZsAAAAJ&hl=en">Google Scholar</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/andrea.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/andrea.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/autorf.jpg' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://niessnerlab.org/projects/mueller2022autorf.html">
                <papertitle>AutoRF: Learning 3D Object Radiance Fields from Single View Observations</papertitle>
              </a>
              <br>
              <a href="https://niessnerlab.org/members/norman_mueller/profile.html">Norman Müller</a>,
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://niessnerlab.org/index.html">Matthias Nießner</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>,
              <br>
        <em>CVPR</em>, 2022  
              <br>
              <a href="https://niessnerlab.org/projects/mueller2022autorf.html">Project page</a>
              <p>From just a single view, we learn neural 3D object representations for free novel view synthesis. This setting is in stark contrast to the majority of existing works that leverage multiple views of the same object, employ explicit priors during training, or require pixel-perfect annotations. Our method decouples object geometry, appearance, and pose enabling generalization to unseen objects, even across different datasets of challenging real-world street scenes such as nuScenes, KITTI, and Mapillary Metropolis.</p>
            </td>
          </tr>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/survey.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2202.02980.pdf">
                <papertitle>3D Object Detection from Images for Autonomous Driving: A Survey</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=8PuKa_8AAAAJ&hl=zh-CN">Xinzhu Ma</a>,
              <a href="https://scholar.google.com/citations?user=pw_0Z_UAAAAJ&hl=zh-CN">Wanli Ouyang</a>,
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=xf1T870AAAAJ&hl=en">Elisa Ricci</a>
              <br>
        <em>Arxiv</em>, 2022  
              <br>
              <a href="https://arxiv.org/pdf/2202.02980.pdf">Arxiv</a>
              <p>3D object detection from images, one of the fundamental and challenging problems in autonomous driving, has received increasing attention from both industry and academia in recent years. Benefiting from the rapid development of deep learning technologies, image-based 3D detection has achieved remarkable progress. Particularly, more than 200 works have studied this problem from 2015 to 2021, encompassing a broad spectrum of theories, algorithms, and applications. However, to date no recent survey exists to collect and organize this knowledge. In this paper, we fill this gap in the literature and provide the first comprehensive survey of this novel and continuously growing research field, summarizing the most commonly used pipelines for image-based 3D detection and deeply analyzing each of their components.</p>
            </td>
          </tr>


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/pseudo_lidar.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Simonelli_Are_We_Missing_Confidence_in_Pseudo-LiDAR_Methods_for_Monocular_3D_ICCV_2021_paper.pdf">
                <papertitle>Are we Missing Confidence in Pseudo-LiDAR Methods for Monocular 3D Object Detection?</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>,
              <a href="https://scholar.google.com/citations?user=xf1T870AAAAJ&hl=en">Elisa Ricci</a>
              <br>
        <em>ICCV</em>, 2021  
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Simonelli_Are_We_Missing_Confidence_in_Pseudo-LiDAR_Methods_for_Monocular_3D_ICCV_2021_paper.pdf">PDF</a>
              <p>We closely analyze a novel branch of 3D Object Detection methods from Images i.e. Pseudo-LiDAR based methods. We identify a flaw in their widely popular training protocol, which introduces a distorted perception about their performance. On top of this, we propose to introduce a novel Absolute and Relative 3D Confidence module which is demonstrated to increase 3D Detection performance substantially.</p>
            </td>
          </tr>


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/virtviews.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1912.08035">
                <papertitle>Towards Generalization Across Depth for Monocular 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=xf1T870AAAAJ&hl=en">Elisa Ricci</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
              <br>
        <em>ECCV</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/1912.08035">arXiv</a>
              <p>We propose to perform the detection, instead of on the usual full-resolution image, on a series of Virtual Views. Virtual Views make the appearence of the objects invariant with respect to distance, easing the overall task. We also propose a single-stage, lightweight architecture called MoVi-3D. We achieve state-of-the-art results on the popular KITTI3D benchmark.</p>
            </td>
          </tr>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/pami.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9200697">
              <papertitle>Disentangling Monocular 3D Object Detection: From Single to Multi-Class Recognition</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=I-t1ZrYAAAAJ&hl=en">Manuel Lòpez Antequera</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
              <br>
        <em>TPAMI</em>, 2020  
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9200697">IEEExplore</a>
              <p>We extend our previous ICCV19 work to the multi-class scenario. In particular, we apply the MonoDIS detector to the challenging nuScenes dataset, achieving comparable results with a LiDAR baseline. In this work we also report updated scores on KITTI3D. </p>
            </td>
          </tr>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/3ddet.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Simonelli_Disentangling_Monocular_3D_Object_Detection_ICCV_2019_paper.pdf">
                <papertitle>Disentangling Monocular 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>,
              <a href="https://scholar.google.com/citations?user=vW1gaVEAAAAJ&hl=en">Lorenzo Porzi</a>,
              <a href="https://scholar.google.com/citations?user=I-t1ZrYAAAAJ&hl=en">Manuel Lòpez Antequera</a>,
              <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
              <br>
        <em>ICCV</em>, 2019  
              <br>
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Simonelli_Disentangling_Monocular_3D_Object_Detection_ICCV_2019_paper.pdf">PDF</a>
              <p>We propose a disentangling transformation which simplifies the training dynamics in the presence of losses with complex interactions of parameters, sidestepping the issue of balancing independent regression terms. We also propose a self-supervised 3D confidence which is very useful to understand the quality of the predicted 3D bounding boxes. In addition, we resolve a flaw in the (now deprecated) KITTI3D metric which affected all the previously published results. Our proposed metric is now the official KITTI3D metric, used to evaluate all methods on the KITTI3D benchmark.</p>
            </td>
          </tr>


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/icip.png' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8451097/">
                <papertitle>Increasingly specialized ensemble of convolutional neural networks for fine-grained recognition</papertitle>
              </a>
              <br>
              <strong>Andrea Simonelli</strong>,
              <a href="https://scholar.google.com/citations?user=Js5-wwcAAAAJ&hl=en">Francesco De Natale</a>,
              <a href="https://scholar.google.com/citations?user=ptAz-SwAAAAJ&hl=en">Stefano Messelodi</a>,
              <a href="https://scholar.google.com/citations?user=484sccEAAAAJ&hl=en">Samuel Rota Bulò</a>
              <br>
        <em>ICIP</em>, 2018 (Oral presentation)
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/8451097/">IEEEXplore</a>
              <p>We propose a simple method for fine-grained recognition that exploits a nearly cost-free attention-based focus operation to construct an ensemble of increasingly specialized Convolutional Neural Networks.</p>
            </td>
          </tr>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Events</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:10px;vertical-align:middle"><img width=100% src="images/logo.png"></td>
            </td>
            <td width="75%" valign="center">
              <a href="https://sites.google.com/unitn.it/3dodi">1st Workshop on 3D Object Detection from Images, ICCV 2021</a>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            </td>
            <td width="75%" valign="center">
              <a href="https://www.nuscenes.org/object-detection?externalData=all&mapData=all&modalities=Any">Winner team of the nuScenes 3D Object Detection Challenge Camera Track, CVPR 2019</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/unitn.png" width="150" height="100"></td>
            <td width="75%" valign="center">
              <p>Student Merit Award, 2018</p>
              <p>Student Merit Award, 2015</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/unitn.png" width="150" height="100"></td>
            <td width="75%" valign="center">
              <p>Advanced Algorithms Teaching Assistant, prof. Elisa Ricci and dr. Samuel Rota Bulò, Spring 2020</p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The source code for this website has been taken from <a href="https://github.com/jonbarron/jonbarron_website"> this</a> nice repo. Last update: March 2022.
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
